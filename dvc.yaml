stages:
  mllam_version:
    cmd: source machines/environment.sh; python -c "from neural_lam import __version__; print(__version__)" > version.mllam.txt
  prepare_dataset:
    cmd: sbatch -W machines/slurm.mllam-data-prep.sh data/datastore.yaml --output data/datastore.zarr
    deps:
    - data/datastore.yaml
    outs:
    - data/datastore.zarr
  create_graph:
    cmd: python -m neural_lam.create_graph --config_path data/config.yaml --name hi4 --levels 4 --hierarchical
    params:
    - data/config.yaml:
      - datastore
    deps:
    - data/datastore.zarr
    outs:
    - data/graph/
  train:
    cmd:
    - sbatch -W machines/slurm.train-neural-lam.sh --config_path ./data/config.yaml --logger mlflow --logger_project neural_lam
    params:
    - data/training_params.yaml:
      - model
      - graph
      - epochs
      - batch_size
      - hidden_dim
      - processor_layers
      - metrics_watch
      - num_workers
      - num_nodes
      - val_steps_to_log
    deps:
    - version.mllam.txt
    - data/graph/
    - data/config.yaml
    - data/datastore.yaml
    outs:
    - saved_models
  evaluate:
    cmd:
    - sbatch -W --nodes 1 machines/slurm.train-neural-lam.sh --config_path ./data/config.yaml --eval val --load
      ./saved_models/*/last.ckpt --logger mlflow --logger_project neural_lam
    params:
    - data/evaluate_params.yaml:
      - model
      - graph
      - epochs
      - batch_size
      - hidden_dim
      - num_workers
      - processor_layers
      - metrics_watch
      - val_steps_to_log
      - num_nodes
      - ar_steps_eval
    deps:
    - version.mllam.txt
    - data/graph/
    - data/config.yaml
    - data/datastore.yaml
    - saved_models
    outs:
    - mlruns
